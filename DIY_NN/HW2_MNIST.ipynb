{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "dataset = 'mnist.pkl.gz'\n",
    "def reporthook(a,b,c):\n",
    "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
    "    \n",
    "if not os.path.isfile(dataset):\n",
    "        origin = \"https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz\"\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urlretrieve(origin, dataset, reporthook=reporthook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data:  50000\n",
      "Length of test data:  10000\n",
      "Class:  10\n"
     ]
    }
   ],
   "source": [
    "cog = len(np.unique(test_set[1]))\n",
    "\n",
    "print(\"Length of train data: \",len(train_set[0]))\n",
    "print(\"Length of test data: \",len(test_set[0]))\n",
    "print(\"Class: \",cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定好訓練及測試資料\n",
    "train_X, train_y = train_set\n",
    "test_X, test_y = test_set\n",
    "# 設定成我們的格式\n",
    "train_X = train_X[..., None]\n",
    "test_X = test_X[..., None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=560x28 at 0x106046278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))\n",
    "# 訓練資料， X 的前 20 筆\n",
    "print(train_y[:20])\n",
    "#print(train_X[:2])\n",
    "showX(train_X[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "# 微分\n",
    "def Drelu(x):\n",
    "    return (x>0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.064 61.08446741354032\n",
      "100 0.476 2.2272008757339004\n",
      "200 0.602 1.331182700931598\n",
      "300 0.63 1.1836834581382\n",
      "400 0.618 1.0717025278112269\n",
      "500 0.654 1.0074608720234601\n",
      "600 0.7 0.884798418723881\n",
      "700 0.704 0.9062967530515122\n",
      "800 0.728 0.7574738521606026\n",
      "900 0.742 0.7490766613064129\n",
      "1000 0.754 0.7077710803970363\n",
      "1100 0.756 0.7908529108710495\n",
      "1200 0.748 0.6967790638480146\n",
      "1300 0.756 0.7359170110339925\n",
      "1400 0.748 0.7236315589066933\n",
      "1500 0.792 0.6309483670939722\n",
      "1600 0.782 0.6365598976098019\n",
      "1700 0.79 0.5757934499798719\n",
      "1800 0.798 0.6078774994520525\n",
      "1900 0.802 0.6443967559958371\n",
      "2000 0.796 0.6221896744197627\n",
      "2100 0.776 0.6773550517800325\n",
      "2200 0.812 0.5776745706188229\n",
      "2300 0.82 0.5990517081142185\n",
      "2400 0.822 0.5797655200899063\n",
      "2500 0.83 0.5437380454561941\n",
      "2600 0.834 0.5484959587108198\n",
      "2700 0.81 0.5975882561572524\n",
      "2800 0.822 0.5489352328500132\n",
      "2900 0.81 0.5998816975881532\n",
      "3000 0.826 0.5545535330636281\n",
      "3100 0.85 0.47788069142860995\n",
      "3200 0.816 0.6282418727262823\n",
      "3300 0.84 0.46208356228302744\n",
      "3400 0.806 0.5719199405984089\n",
      "3500 0.816 0.5729344113838488\n",
      "3600 0.832 0.5730012746856279\n",
      "3700 0.846 0.5399179453356157\n",
      "3800 0.82 0.6114300717570982\n",
      "3900 0.85 0.5101624537158937\n",
      "4000 0.858 0.4567181382558718\n",
      "4100 0.83 0.5896276287609582\n",
      "4200 0.818 0.5567716906583202\n",
      "4300 0.824 0.6290849243289774\n",
      "4400 0.84 0.48488882509596914\n",
      "4500 0.842 0.5307021440520306\n",
      "4600 0.806 0.5920493840057637\n",
      "4700 0.822 0.5215987350706127\n",
      "4800 0.858 0.43740956158159805\n",
      "4900 0.86 0.513164949281427\n",
      "5000 0.844 0.5702915496933181\n",
      "5100 0.86 0.4759088485395507\n",
      "5200 0.088 53.132085142481934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonyguo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/tonyguo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/tonyguo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in maximum\n",
      "  \n",
      "/Users/tonyguo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 0.106 nan\n",
      "5400 0.128 nan\n",
      "5500 0.116 nan\n",
      "5600 0.094 nan\n",
      "5700 0.094 nan\n",
      "5800 0.122 nan\n",
      "5900 0.102 nan\n"
     ]
    }
   ],
   "source": [
    "# 參考範例 softmax regression\n",
    "W = np.random.normal(size=(25, 784))\n",
    "W2 = np.random.normal(size=(10, 25))\n",
    "b = np.random.normal(size=(25, 1))\n",
    "\n",
    "c = np.random.normal(size=(10, 1))\n",
    "\n",
    "n_data = train_X.shape[0]\n",
    "# 紀錄 loss\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "for epoch in range(6000):    \n",
    "    idx = np.random.choice(n_data, 500, replace=False)\n",
    "    X = train_X[idx]\n",
    "    y = train_y[idx]\n",
    "    one_y = np.eye(10)[y][..., None]\n",
    "    \n",
    "    A = W @ X + b\n",
    "    ta = relu(A)\n",
    "    \n",
    "    \n",
    "    d = np.exp(W2 @ ta + c)\n",
    "    q = d/d.sum(axis=(1,2), keepdims=True)\n",
    "    loss = -np.log(q[range(len(y)), y]).mean()\n",
    "    loss_history.append(loss)\n",
    "    accuracy = (q.argmax(axis=1).ravel() == y).mean()\n",
    "    accuracy_history.append(accuracy)\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch, accuracy, loss)\n",
    "    grad_W2_all = q - one_y\n",
    "    \n",
    "    grad_W2 = grad_W2_all @ ta.swapaxes(1,2)\n",
    "    grad_W2 = grad_W2.mean(axis=0)\n",
    "    #print(W2.T.shape)\n",
    "    \n",
    "    grad_ta_all = np.array([W2.T @ t for t in grad_W2_all])\n",
    "    #grad_ta_all = W2.swapaxes(1,2) @ grad_w2_all\n",
    "\n",
    "    grad_ta = grad_ta_all*Drelu(A)\n",
    "    #print((1-pow(np.tanh(grad_ta_all),2)).shape)\n",
    "    grad_b = grad_ta.mean(axis=0)\n",
    "    \n",
    "    grad_W = grad_ta @ X.swapaxes(1,2)\n",
    "    grad_W = grad_W.mean(axis=0)\n",
    "    #print(grad_W.shape)\n",
    "    #grad_W = grad_W_all.mean(axis=0)\n",
    "    #W -= grad_W\n",
    "    #b -= grad_b    \n",
    "    W -=  0.1*((5001-epoch)/5000)*grad_W\n",
    "    W2 -=  0.1*((5001-epoch)/5000)*grad_W2\n",
    "    b -= 0.1*((5001-epoch)/5000)*grad_b    \n",
    "    c -= 0.1*((5001-epoch)/5000)*grad_W2_all.mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean-square-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.082 190323.22517583327\n",
      "100 0.1 0.17163747832973397\n"
     ]
    }
   ],
   "source": [
    "# 參考範例 softmax regression\n",
    "W = np.random.normal(size=(25, 784))\n",
    "W2 = np.random.normal(size=(10, 25))\n",
    "b = np.random.normal(size=(25, 1))\n",
    "\n",
    "c = np.random.normal(size=(10, 1))\n",
    "\n",
    "n_data = train_X.shape[0]\n",
    "# 紀錄 loss\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "for epoch in range(6000):    \n",
    "    idx = np.random.choice(n_data, 500, replace=False)\n",
    "    X = train_X[idx]\n",
    "    y = train_y[idx]\n",
    "    one_y = np.eye(10)[y][..., None]\n",
    "    \n",
    "    A = W @ X + b\n",
    "    ta = relu(A)\n",
    "    \n",
    "    d = W2 @ ta + c\n",
    "    #d = np.exp(W2 @ ta + c)\n",
    "    q = d/d.sum(axis=(1,2), keepdims=True)\n",
    "    #loss = -np.log(q[range(len(y)), y]).mean()\n",
    "    loss = np.array([(q[t]- one_y[t]).T@(q[t]- one_y[t]) for t in range(len(q))])\n",
    "    #print(loss.mean(axis=1).shape)\n",
    "    loss = ((loss.mean(axis=1))/len(one_y[0])).mean()\n",
    "    #print(loss.mean().shape)\n",
    "    loss_history.append(loss)\n",
    "    accuracy = (q.argmax(axis=1).ravel() == y).mean()\n",
    "    accuracy_history.append(accuracy)\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch, accuracy, loss)\n",
    "        #print(\"\")\n",
    "    #grad_W2_all = q - one_y\n",
    "    \n",
    "    #print((d*one_y).shape)\n",
    "    grad_W2_all = (2/len(one_y[0]))*(d*one_y)\n",
    "    #print(grad_W2_all.shape)\n",
    "    grad_W2_all = grad_W2_all*np.array([(-1)*(q[t].T@one_y[t])*(q[t]-one_y[t]) for t in range(len(q))])\n",
    "    \n",
    "    grad_W2 = grad_W2_all @ ta.swapaxes(1,2)\n",
    "    grad_W2 = grad_W2.mean(axis=0)\n",
    "    #print(W2.T.shape)\n",
    "    \n",
    "    grad_ta_all = np.array([W2.T @ t for t in grad_W2_all])\n",
    "    #grad_ta_all = W2.swapaxes(1,2) @ grad_w2_all\n",
    "\n",
    "    grad_ta = grad_ta_all*Drelu(A)\n",
    "    #print((1-pow(np.tanh(grad_ta_all),2)).shape)\n",
    "    grad_b = grad_ta.mean(axis=0)\n",
    "    \n",
    "    grad_W = grad_ta @ X.swapaxes(1,2)\n",
    "    grad_W = grad_W.mean(axis=0)\n",
    "    #print(grad_W.shape)\n",
    "    #grad_W = grad_W_all.mean(axis=0)\n",
    "    #W -= grad_W\n",
    "    #b -= grad_b    \n",
    "    W -=  0.1*((5001-epoch)/5000)*grad_W\n",
    "    W2 -=  0.1*((5001-epoch)/5000)*grad_W2\n",
    "    b -= 0.1*((5001-epoch)/5000)*grad_b    \n",
    "    c -= 0.1*((5001-epoch)/5000)*grad_W2_all.mean(axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
